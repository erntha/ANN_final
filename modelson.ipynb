{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Function to parse filenames and extract labels\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    # Parse initial position\n",
    "    if parts[1] == 'tura':\n",
    "        initial_position = 0\n",
    "    elif parts[1] == 'yazi':\n",
    "        initial_position = 1\n",
    "    elif parts[1] == 'vert':\n",
    "        initial_position = 2\n",
    "    else:\n",
    "        raise ValueError(\"Unknown initial position in filename\")\n",
    "\n",
    "    # Parse distance\n",
    "    distance = float(parts[2].replace('cm', ''))\n",
    "\n",
    "    # Parse binary label, check last part before \".png\"\n",
    "    binary_label_part = parts[-1].split('.')[0]\n",
    "    binary_label = 0 if binary_label_part == 'tura' else 1\n",
    "\n",
    "    return initial_position, distance, binary_label\n",
    "\n",
    "# Custom dataset class\n",
    "class CoinDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        # Sort the filenames numerically\n",
    "        self.image_filenames = sorted(os.listdir(image_folder), key=lambda x: int(x.split('_')[0]))\n",
    "        # Extract labels\n",
    "        self.initial_positions, self.distance_labels, self.binary_labels = self.extract_labels()\n",
    "\n",
    "    def extract_labels(self):\n",
    "        initial_positions = []\n",
    "        distance_labels = []\n",
    "        binary_labels = []\n",
    "\n",
    "        for filename in self.image_filenames:\n",
    "            initial_position, distance, binary_label = parse_filename(filename)\n",
    "            initial_positions.append(initial_position)\n",
    "            distance_labels.append(distance)\n",
    "            binary_labels.append(binary_label)\n",
    "\n",
    "        return initial_positions, distance_labels, binary_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_filenames[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        binary_label = self.binary_labels[idx]\n",
    "        distance_label = self.distance_labels[idx]\n",
    "        initial_position = self.initial_positions[idx]\n",
    "\n",
    "        return image, binary_label, distance_label, initial_position\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/home/eren/Desktop/para/dataset/datason'\n",
    "dataset = CoinDataset(image_folder=folder_path, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model_cointoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_cointoss, self).__init__()\n",
    "        # Define the CNN layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Dense layers\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(2560001,128),  # +1 for the integer label, adjust the input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Output layers\n",
    "        self.classification_output = nn.Linear(64, 1)  # Single neuron for binary classification\n",
    "        self.regression_output = nn.Linear(64, 1)  # Single neuron for regression output\n",
    "\n",
    "    def forward(self, x, label):\n",
    "        # Process the image through the convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Combine the image features with the label\n",
    "        combined = torch.cat((x, label.unsqueeze(1)), dim=1)\n",
    "        \n",
    "        # Pass through dense layers\n",
    "        combined = self.dense_layers(combined)\n",
    "        \n",
    "        # Get the classification (using sigmoid for binary classification) and regression outputs\n",
    "        class_output = torch.sigmoid(self.classification_output(combined))\n",
    "        reg_output = self.regression_output(combined)\n",
    "        \n",
    "        return class_output, reg_output\n",
    "\n",
    "# Instantiate the model\n",
    "model = Model_cointoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Backpropagation on GPU using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 120.93118286132812\n",
      "Epoch [2/10], Loss: 1390.7713623046875\n",
      "Epoch [3/10], Loss: 23.925704956054688\n",
      "Epoch [4/10], Loss: 518.0977172851562\n",
      "Epoch [5/10], Loss: 288.93133544921875\n",
      "Epoch [6/10], Loss: 437.76385498046875\n",
      "Epoch [7/10], Loss: 54.88039779663086\n",
      "Epoch [8/10], Loss: 2.9349398612976074\n",
      "Epoch [9/10], Loss: 62.506996154785156\n",
      "Epoch [10/10], Loss: 87.97881317138672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loss functions\n",
    "classification_loss_fn = nn.BCELoss()\n",
    "regression_loss_fn = nn.MSELoss()\n",
    "\n",
    "# Transfer the model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, binary_labels, distance_labels, initial_positions in dataloader:\n",
    "        # Transfer data to GPU\n",
    "        images = images.to(device)\n",
    "        binary_labels = binary_labels.to(device).view(-1, 1).type(torch.float)\n",
    "        distance_labels = distance_labels.to(device).view(-1, 1).type(torch.float)\n",
    "        initial_positions = initial_positions.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_binary_labels, predicted_distance_labels = model(images, initial_positions)\n",
    "\n",
    "        # Calculate loss\n",
    "        classification_loss = classification_loss_fn(predicted_binary_labels, binary_labels)\n",
    "        regression_loss = regression_loss_fn(predicted_distance_labels, distance_labels)\n",
    "        total_loss = classification_loss + regression_loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print epoch's loss after each epoch (optional)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model state dict to a file\n",
    "torch.save(model.state_dict(), 'model_ann.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
